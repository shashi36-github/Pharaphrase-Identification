{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymsItxRbWC1f",
        "outputId": "d054ac65-25a7-41ca-d520-9dc4b0d522b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (0.11.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n",
            "E: Package 'libfluidsynth1' has no installation candidate\n",
            "Collecting python-libarchive\n",
            "  Downloading python_libarchive-4.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-libarchive\n",
            "Successfully installed python-libarchive-4.2.1\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting libarchive\n",
            "  Downloading libarchive-0.4.7.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nose (from libarchive)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for libarchive\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for libarchive\n",
            "Failed to build libarchive\n",
            "\u001b[31mERROR: Could not build wheels for libarchive, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n",
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.0)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3.1->cartopy) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n",
            "Installing collected packages: cartopy\n",
            "Successfully installed cartopy-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib-venn\n",
        "!apt-get -qq install -y libfluidsynth1\n",
        "!pip install python-libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot\n",
        "!pip install cartopy\n",
        "import cartopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxKmBCOmuLxK",
        "outputId": "b93752bf-9185-4aca-ce33-aa164f06ade4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting data\n",
            "  Downloading data-0.4.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from data) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from data) (4.4.2)\n",
            "Collecting funcsigs (from data)\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: data\n",
            "  Building wheel for data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for data: filename=data-0.4-py3-none-any.whl size=7228 sha256=ed032ba086cdfbc1251958072aabe87c220da7fafa543fab7358ca3fa6d25e73\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/e8/fa/e253c256048ea58d99a8abb5e751abb6a838af6f12887b5418\n",
            "Successfully built data\n",
            "Installing collected packages: funcsigs, data\n",
            "Successfully installed data-0.4 funcsigs-1.0.2\n",
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.9.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.6.0\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            23.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.14.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.2.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.3.4\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.1\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.3.3\n",
            "Cartopy                          0.23.0\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.2.2\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.16.0\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.9\n",
            "cmdstanpy                        1.2.2\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.4\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     42.0.5\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.3\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.10\n",
            "dask                             2023.8.1\n",
            "data                             0.4\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.2.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.4\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.10.2\n",
            "earthengine-api                  0.1.399\n",
            "easydict                         1.13\n",
            "ecos                             2.0.13\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.2.1\n",
            "fastai                           2.7.14\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.19.1\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.13.4\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.2\n",
            "folium                           0.14.0\n",
            "fonttools                        4.51.0\n",
            "frozendict                       2.4.2\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2023.6.0\n",
            "funcsigs                         1.0.2\n",
            "future                           0.18.3\n",
            "gast                             0.5.4\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.32.0\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.4.0\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.2.0\n",
            "google-cloud-aiplatform          1.48.0\n",
            "google-cloud-bigquery            3.12.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.24.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.15.0\n",
            "google-cloud-language            2.13.3\n",
            "google-cloud-resource-manager    1.12.3\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.3.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.0\n",
            "googleapis-common-protos         1.63.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.0\n",
            "grpcio                           1.62.2\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.47\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.20.3\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib_metadata               7.1.0\n",
            "importlib_resources              6.4.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "intel-openmp                     2023.2.4\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.3\n",
            "joblib                           1.4.0\n",
            "jsonpickle                       3.0.4\n",
            "jsonschema                       4.19.2\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.10\n",
            "kaggle                           1.5.16\n",
            "kagglehub                        0.2.3\n",
            "keras                            2.15.0\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.3.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.1\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.3\n",
            "llvmlite                         0.41.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2023.1067\n",
            "Markdown                         3.6\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.58.1\n",
            "numexpr                          2.10.0\n",
            "numpy                            1.25.2\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.9.0.80\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "orbax-checkpoint                 0.4.4\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        24.0\n",
            "pandas                           2.0.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     2.0.3.230814\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.3.8\n",
            "param                            2.1.0\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.3\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     4.2.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.4.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.1\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.10.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.43\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.23.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          14.0.2\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.22\n",
            "pydantic                         2.7.0\n",
            "pydantic_core                    2.18.1\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.1.0\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.0.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-libarchive                4.2.1\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2023.4\n",
            "pyviz_comms                      3.0.2\n",
            "PyWavelets                       1.6.0\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post2\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.34.0\n",
            "regex                            2023.12.25\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rpds-py                          0.18.0\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.3\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.4\n",
            "scooby                           0.9.2\n",
            "scs                              3.2.4.post1\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.4\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.7.4\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.8\n",
            "sphinxcontrib-devhelp            1.0.6\n",
            "sphinxcontrib-htmlhelp           2.0.5\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.7\n",
            "sphinxcontrib-serializinghtml    1.1.10\n",
            "SQLAlchemy                       2.0.29\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.0\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.0\n",
            "statsmodels                      0.14.2\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.12.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      2.15.2\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.15.0\n",
            "tensorflow-datasets              4.9.4\n",
            "tensorflow-estimator             2.15.0\n",
            "tensorflow-gcs-config            2.15.0\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.36.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-probability           0.23.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.15.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.3\n",
            "threadpoolctl                    3.4.0\n",
            "tifffile                         2024.4.18\n",
            "tinycss2                         1.2.1\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.1\n",
            "torch                            2.2.1+cu121\n",
            "torchaudio                       2.2.1+cu121\n",
            "torchdata                        0.7.1\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.17.1\n",
            "torchvision                      0.17.1+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.2\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.40.0\n",
            "triton                           2.2.0\n",
            "tweepy                           4.14.0\n",
            "typer                            0.9.4\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 69.5.0.20240423\n",
            "typing_extensions                4.11.0\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.3.4\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.7.0\n",
            "Werkzeug                         3.0.2\n",
            "wheel                            0.43.0\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.0.3\n",
            "xlrd                             2.0.1\n",
            "xyzservices                      2024.4.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.38\n",
            "zict                             3.0.0\n",
            "zipp                             3.18.1\n"
          ]
        }
      ],
      "source": [
        "!pip install data\n",
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk5uBRVtoLwt",
        "outputId": "de073a86-bad8-42e7-c894-7c9e26eb0af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting theano\n",
            "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from theano) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from theano) (1.11.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from theano) (1.16.0)\n",
            "Building wheels for collected packages: theano\n",
            "  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano: filename=Theano-1.0.5-py3-none-any.whl size=2668109 sha256=405d1d81e5362316d56aa1052ea28e5291331451e1d54b1deabcff097c8ffb2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/e6/7d/2267d21a99e4ab8276f976f293b4ff23f50c9d809f4a216ebb\n",
            "Successfully built theano\n",
            "Installing collected packages: theano\n",
            "Successfully installed theano-1.0.5\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.10/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from theano) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from theano) (1.11.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from theano) (1.16.0)\n",
            "/bin/bash: line 1: conda: command not found\n",
            "Name: Theano\n",
            "Version: 1.0.5\n",
            "Summary: Optimizing compiler for evaluating mathematical expressions on CPUs and GPUs.\n",
            "Home-page: http://deeplearning.net/software/theano/\n",
            "Author: LISA laboratory, University of Montreal\n",
            "Author-email: theano-dev@googlegroups.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, scipy, six\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip install theano\n",
        "!pip install --upgrade theano\n",
        "!conda install theano\n",
        "!pip show theano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc1Ie-OzNqh1"
      },
      "source": [
        "Paraphrase Identification between multiple text files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_d7NW68Nb19",
        "outputId": "121874a7-66fe-4e68-b59d-e0b26a3a0abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Evaluating files 1 and 2:   0%|          | 0/2 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 1 and 2:  50%|█████     | 1/2 [00:05<00:05,  5.02s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 1 and 2: 100%|██████████| 2/2 [00:06<00:00,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similarity Scores for File Pairs:\n",
            "File 1 & File 2: Similarity Score = 0.20\n",
            "\n",
            "Similar Sentence Pairs for File Pairs:\n",
            "\n",
            "File 1 & File 2:\n",
            "  Sentence 1: \n",
            "  Sentence 2: \n",
            "  Sentence 1: \n",
            "  Sentence 2: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "\n",
        "class ParaphraseDataset(Dataset):\n",
        "    def __init__(self, sentence_pairs, tokenizer, max_length=128):\n",
        "        self.sentence_pairs = sentence_pairs\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentence_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence1, sentence2 = self.sentence_pairs[idx]\n",
        "        inputs = self.tokenizer(sentence1, sentence2, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
        "            'sentence1': sentence1,\n",
        "            'sentence2': sentence2,\n",
        "        }\n",
        "\n",
        "class BERTForParaphraseDetection(torch.nn.Module):\n",
        "    def __init__(self, pretrained_model_name):\n",
        "        super(BERTForParaphraseDetection, self).__init__()\n",
        "        self.model = BertForSequenceClassification.from_pretrained(pretrained_model_name)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.logits\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def load_sentences(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return [line.strip() for line in f]\n",
        "\n",
        "file_paths = [\"/content/Text_file-1.txt\", \"/content/Text_file-2.txt\"]\n",
        "\n",
        "file_sentences = [load_sentences(file_path) for file_path in file_paths]\n",
        "\n",
        "file_combinations = list(itertools.combinations(enumerate(file_sentences), 2))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BERTForParaphraseDetection('bert-base-uncased')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "similarity_threshold = 0.5\n",
        "\n",
        "similarity_scores = {}\n",
        "similar_sentence_pairs = {}  # Dictionary to store similar sentence pairs\n",
        "\n",
        "for (idx1, sentences1), (idx2, sentences2) in file_combinations:\n",
        "    sentence_pairs = [(s1, s2) for s1 in sentences1 for s2 in sentences2]\n",
        "\n",
        "    dataset = ParaphraseDataset(sentence_pairs, tokenizer)\n",
        "    dataloader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    paraphrase_count = 0\n",
        "    total_pairs = len(sentence_pairs)\n",
        "\n",
        "    # Initialize a list to store similar sentence pairs for the current file pair\n",
        "    similar_pairs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=f\"Evaluating files {idx1+1} and {idx2+1}\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # Iterate through predictions\n",
        "            for i, pred in enumerate(predictions):\n",
        "                if pred == 1:  # If the prediction is a paraphrase\n",
        "                    paraphrase_count += 1\n",
        "                    # Add similar sentence pair to the list\n",
        "                    sentence1 = batch['sentence1'][i]\n",
        "                    sentence2 = batch['sentence2'][i]\n",
        "                    similar_pairs.append((sentence1, sentence2))\n",
        "\n",
        "    # Calculate similarity score\n",
        "    similarity_score = paraphrase_count / total_pairs\n",
        "    pair_name = f\"File {idx1+1} & File {idx2+1}\"\n",
        "    similarity_scores[pair_name] = similarity_score\n",
        "\n",
        "    # Store the similar pairs for the current file pair\n",
        "    similar_sentence_pairs[pair_name] = similar_pairs\n",
        "\n",
        "# Print similarity scores for each file pair\n",
        "print(\"\\nSimilarity Scores for File Pairs:\")\n",
        "for pair, score in similarity_scores.items():\n",
        "    print(f\"{pair}: Similarity Score = {score:.2f}\")\n",
        "\n",
        "# Print similar sentence pairs for each file pair\n",
        "print(\"\\nSimilar Sentence Pairs for File Pairs:\")\n",
        "for pair_name, pairs in similar_sentence_pairs.items():\n",
        "    if len(pairs) > 0:\n",
        "        print(f\"\\n{pair_name}:\")\n",
        "        for sentence1, sentence2 in pairs:\n",
        "            print(f\"  Sentence 1: {sentence1}\")\n",
        "            print(f\"  Sentence 2: {sentence2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxxK0FSKuayC",
        "outputId": "1a05a7f2-556e-492c-e63c-2b346d831da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.11.0)\n"
          ]
        }
      ],
      "source": [
        "pip install python-docx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1FxbAZwOO5A"
      },
      "source": [
        "Paraphrase Identification between multiple Word documents\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import os\n",
        "from docx import Document\n",
        "class ParaphraseDataset(Dataset):\n",
        "    def __init__(self, sentence_pairs, tokenizer, max_length=128):\n",
        "        self.sentence_pairs = sentence_pairs\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self):\n",
        "        return len(self.sentence_pairs)\n",
        "    def __getitem__(self, idx):\n",
        "        sentence1, sentence2 = self.sentence_pairs[idx]\n",
        "        inputs = self.tokenizer(sentence1, sentence2, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
        "            'sentence1': sentence1,\n",
        "            'sentence2': sentence2,\n",
        "        }\n",
        "class BERTForParaphraseDetection(torch.nn.Module):\n",
        "    def __init__(self, pretrained_model_name):\n",
        "        super(BERTForParaphraseDetection, self).__init__()\n",
        "        self.model = BertForSequenceClassification.from_pretrained(pretrained_model_name)\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.logits\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text.append(paragraph.text)\n",
        "    return text\n",
        "\n",
        "file_paths = [\"/content/The Taj Mahal-1.docx\",\"/content/The Taj Mahal.docx\", \"/content/The Great Wall of China.docx\"]\n",
        "\n",
        "file_sentences = [extract_text_from_docx(file_path) for file_path in file_paths]\n",
        "\n",
        "file_combinations = list(itertools.combinations(enumerate(file_sentences), 2))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BERTForParaphraseDetection('bert-base-uncased')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "similarity_threshold = 0.5\n",
        "similarity_scores = {}\n",
        "similar_sentence_pairs = {}\n",
        "for (idx1, sentences1), (idx2, sentences2) in file_combinations:\n",
        "    sentence_pairs = [(s1, s2) for s1 in sentences1 for s2 in sentences2]\n",
        "    dataset = ParaphraseDataset(sentence_pairs, tokenizer)\n",
        "    dataloader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
        "    paraphrase_count = 0\n",
        "    total_pairs = len(sentence_pairs)\n",
        "    similar_pairs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=f\"Evaluating files {idx1+1} and {idx2+1}\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "            for i, pred in enumerate(predictions):\n",
        "                if pred == 1:\n",
        "                    paraphrase_count += 1\n",
        "                    sentence1 = batch['sentence1'][i]\n",
        "                    sentence2 = batch['sentence2'][i]\n",
        "                    similar_pairs.append((sentence1, sentence2))\n",
        "    similarity_score = paraphrase_count / total_pairs\n",
        "    pair_name = f\"File {idx1+1} & File {idx2+1}\"\n",
        "    similarity_scores[pair_name] = similarity_score\n",
        "    similar_sentence_pairs[pair_name] = similar_pairs\n",
        "print(\"\\nSimilarity Scores for File Pairs:\")\n",
        "for pair, score in similarity_scores.items():\n",
        "    print(f\"{pair}: Similarity Score = {score:.2f}\")\n",
        "print(\"\\nSimilar Sentence Pairs for File Pairs:\")\n",
        "for pair_name, pairs in similar_sentence_pairs.items():\n",
        "    if len(pairs) > 0:\n",
        "        print(f\"\\n{pair_name}:\")\n",
        "        for sentence1, sentence2 in pairs:\n",
        "            print(f\"  Sentence 1: {sentence1}\")\n",
        "            print(f\"  Sentence 2: {sentence2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Miaz4_WYwvd",
        "outputId": "ae9040d1-26ad-4a11-b29e-acd8561df9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Evaluating files 1 and 2:   0%|          | 0/2 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 1 and 2:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 1 and 2: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]\n",
            "Evaluating files 1 and 3:   0%|          | 0/2 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 1 and 3:  50%|█████     | 1/2 [00:03<00:03,  3.67s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 1 and 3: 100%|██████████| 2/2 [00:05<00:00,  2.55s/it]\n",
            "Evaluating files 2 and 3:   0%|          | 0/2 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 2 and 3:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Evaluating files 2 and 3: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similarity Scores for File Pairs:\n",
            "File 1 & File 2: Similarity Score = 0.00\n",
            "File 1 & File 3: Similarity Score = 0.08\n",
            "File 2 & File 3: Similarity Score = 0.11\n",
            "\n",
            "Similar Sentence Pairs for File Pairs:\n",
            "\n",
            "File 1 & File 3:\n",
            "  Sentence 1: The Taj Mahal, one of the most iconic landmarks in the world, is located in Agra, India. Commissioned in 1632 by the Mughal emperor Shah Jahan in memory of his beloved wife Mumtaz Mahal, the monument stands as a testament to eternal love and exquisite craftsmanship. It took over 20,000 artisans from across the empire and beyond to construct the Taj Mahal, with construction spanning over two decades, completing in 1653. Its stunning white marble facade is adorned with intricate carvings and inlaid with semi-precious stones, showcasing the finest examples of Mughal architecture.\n",
            "  Sentence 2: The Great Wall of China is an iconic symbol of China's rich history and engineering prowess. Stretching over 13,000 miles across northern China, it is one of the most impressive architectural feats ever constructed. Originally built over several centuries, starting as early as the 7th century BC, the wall served as a defensive barrier against invasions from nomadic tribes to the north, particularly during the Ming Dynasty (1368-1644 AD), when the majority of the existing wall was constructed.\n",
            "\n",
            "File 2 & File 3:\n",
            "  Sentence 1: The Taj Mahal, one of the most iconic landmarks in the world, is located in Agra, India. Commissioned in 1632 by the Mughal emperor Shah Jahan in memory of his beloved wife Mumtaz Mahal, the monument stands as a testament to eternal love and exquisite craftsmanship. It took over 20,000 artisans from across the empire and beyond to construct the Taj Mahal, with construction spanning over two decades, completing in 1653. Its stunning white marble facade is adorned with intricate carvings and inlaid with semi-precious stones, showcasing the finest examples of Mughal architecture.\n",
            "  Sentence 2: The Great Wall of China is an iconic symbol of China's rich history and engineering prowess. Stretching over 13,000 miles across northern China, it is one of the most impressive architectural feats ever constructed. Originally built over several centuries, starting as early as the 7th century BC, the wall served as a defensive barrier against invasions from nomadic tribes to the north, particularly during the Ming Dynasty (1368-1644 AD), when the majority of the existing wall was constructed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}